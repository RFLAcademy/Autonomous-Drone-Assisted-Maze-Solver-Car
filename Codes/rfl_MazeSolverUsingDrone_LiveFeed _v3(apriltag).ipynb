{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "two phase strategy - capturing image and detecting path, followed by live video feed and april tag tracking (first phase does not use live video - instead looks for two concurrent images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import grey_dilation\n",
        "from pupil_apriltags import Detector\n",
        "\n",
        "CELL_SIZE = 20\n",
        "DETECTOR = Detector(families='tag36h11')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pixel_to_grid(pixel, cell_size=CELL_SIZE):\n",
        "    return (pixel[1] // cell_size, pixel[0] // cell_size)\n",
        "\n",
        "def grid_to_pixel(grid, cell_size=CELL_SIZE):\n",
        "    return (grid[1] * cell_size + cell_size // 2, grid[0] * cell_size + cell_size // 2)\n",
        "\n",
        "def resize_for_pathfinding(mask, factor):\n",
        "    small = cv2.resize(mask, (mask.shape[1] // factor, mask.shape[0] // factor), interpolation=cv2.INTER_NEAREST)\n",
        "    return (small > 0).astype(np.uint8)\n",
        "\n",
        "def inflate_obstacles(grid, inflation_radius=1):\n",
        "    return grey_dilation(grid, size=(2 * inflation_radius + 1, 2 * inflation_radius + 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_start_end_obstacles(image):\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    green_mask = cv2.inRange(hsv, (40, 40, 40), (80, 255, 255))   # Start\n",
        "    blue_mask = cv2.inRange(hsv, (100, 150, 0), (140, 255, 255))  # End\n",
        "    orange_mask = cv2.inRange(hsv, (5, 150, 150), (20, 255, 255)) # Obstacles\n",
        "\n",
        "    def find_centroid(mask):\n",
        "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        if contours:\n",
        "            largest = max(contours, key=cv2.contourArea)\n",
        "            M = cv2.moments(largest)\n",
        "            if M[\"m00\"] != 0:\n",
        "                cx = int(M[\"m10\"] / M[\"m00\"])\n",
        "                cy = int(M[\"m01\"] / M[\"m00\"])\n",
        "                return (cx, cy)\n",
        "        return None\n",
        "\n",
        "    return find_centroid(green_mask), find_centroid(blue_mask), orange_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def heuristic(a, b):\n",
        "    return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
        "\n",
        "def astar(grid, start, end):\n",
        "    import heapq\n",
        "    neighbors = [(0,1),(1,0),(-1,0),(0,-1)]\n",
        "    close_set = set()\n",
        "    came_from = {}\n",
        "    gscore = {start: 0}\n",
        "    fscore = {start: heuristic(start, end)}\n",
        "    oheap = [(fscore[start], start)]\n",
        "\n",
        "    while oheap:\n",
        "        _, current = heapq.heappop(oheap)\n",
        "        if current == end:\n",
        "            path = []\n",
        "            while current in came_from:\n",
        "                path.append(current)\n",
        "                current = came_from[current]\n",
        "            path.append(start)\n",
        "            path.reverse()\n",
        "            return path\n",
        "\n",
        "        close_set.add(current)\n",
        "        for i, j in neighbors:\n",
        "            neighbor = (current[0]+i, current[1]+j)\n",
        "            if 0 <= neighbor[0] < grid.shape[0] and 0 <= neighbor[1] < grid.shape[1]:\n",
        "                if grid[neighbor[0]][neighbor[1]] == 1:\n",
        "                    continue\n",
        "            else:\n",
        "                continue\n",
        "            tentative_g = gscore[current] + 1\n",
        "            if neighbor in close_set and tentative_g >= gscore.get(neighbor, 0):\n",
        "                continue\n",
        "            if tentative_g < gscore.get(neighbor, float('inf')):\n",
        "                came_from[neighbor] = current\n",
        "                gscore[neighbor] = tentative_g\n",
        "                fscore[neighbor] = tentative_g + heuristic(neighbor, end)\n",
        "                heapq.heappush(oheap, (fscore[neighbor], neighbor))\n",
        "    return []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m frame = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     ret, frame = \u001b[43mcap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[32m      9\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture(1)  # or 0 depending on your webcam\n",
        "path = []\n",
        "path_pixels = []\n",
        "frame = None\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        continue\n",
        "\n",
        "    start, end, obstacles = detect_start_end_obstacles(frame)\n",
        "    if start and end:\n",
        "        start_g = pixel_to_grid(start)\n",
        "        end_g = pixel_to_grid(end)\n",
        "        obs_grid = resize_for_pathfinding(obstacles, CELL_SIZE)\n",
        "        inflated = inflate_obstacles(obs_grid, inflation_radius=1)\n",
        "        path = astar(inflated, start_g, end_g)\n",
        "        if path:\n",
        "            path_pixels = [grid_to_pixel(pt) for pt in path]\n",
        "            break  # STOP after first valid path found\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# === Draw the path on the image ===\n",
        "output = frame.copy()\n",
        "\n",
        "# Draw the path with circles\n",
        "for pt in path_pixels:\n",
        "    cv2.circle(output, pt, 2, (0, 0, 0), -1)  # Black dots\n",
        "\n",
        "# Start and end markers\n",
        "if path_pixels:\n",
        "    cv2.circle(output, path_pixels[0], 5, (0, 255, 0), -1)   # Green = Start\n",
        "    cv2.circle(output, path_pixels[-1], 5, (255, 0, 0), -1)  # Blue = End\n",
        "\n",
        "# Show image with matplotlib (side-by-side original and path)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Path Detected\")\n",
        "plt.imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_apriltag(frame, target_id=0):\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    results = DETECTOR.detect(gray)\n",
        "    for r in results:\n",
        "        if r.tag_id == target_id:\n",
        "            center = tuple(map(int, r.center))\n",
        "            return center\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "cap = cv2.VideoCapture(1)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    robot_pos = detect_apriltag(frame)\n",
        "    display = frame.copy()\n",
        "\n",
        "    # Draw path\n",
        "    for pt in path_pixels:\n",
        "        cv2.circle(display, pt, 2, (0, 0, 0), -1)\n",
        "\n",
        "    # Robot position\n",
        "    if robot_pos:\n",
        "        cv2.circle(display, robot_pos, 6, (0, 0, 255), -1)\n",
        "\n",
        "    # Start & End points\n",
        "    if path_pixels:\n",
        "        cv2.circle(display, path_pixels[0], 5, (0, 255, 0), -1)   # Start (Green)\n",
        "        cv2.circle(display, path_pixels[-1], 5, (255, 0, 0), -1)  # End (Blue)\n",
        "\n",
        "    cv2.imshow(\"Robot Tracking with AprilTag\", display)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
